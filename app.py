import streamlit as st
import pandas as pd
import uuid
from datetime import date, timedelta, datetime
import os
from io import StringIO
from github import Github, GithubException
from openai import OpenAI

# ==============================================================================
# 1. é…ç½®ä¸åˆå§‹åŒ–
# ==============================================================================

st.set_page_config(
    page_title="MemoFlow",
    page_icon="ğŸ§ ",
    layout="wide"
)

# å®šä¹‰æ•°æ®ç»“æ„æ ‡å‡†
REQUIRED_COLUMNS = [
    'id', 'term', 'definition', 'context', 
    'last_review', 'next_review', 'interval', 
    'repetitions', 'ease_factor', 'status'
]

# åˆå§‹åŒ– Session State
if 'data' not in st.session_state:
    st.session_state.data = pd.DataFrame(columns=REQUIRED_COLUMNS)
if 'show_answer' not in st.session_state:
    st.session_state.show_answer = False
if 'current_card_id' not in st.session_state:
    st.session_state.current_card_id = None

# ==============================================================================
# 2. æ ¸å¿ƒé€»è¾‘ï¼šSM-2 ç®—æ³• & GitHub åŒæ­¥
# ==============================================================================

class SRSManager:
    @staticmethod
    def calculate_next_review(row, quality):
        """SM-2 ç®—æ³•å®ç°"""
        reps = int(row['repetitions'])
        ef = float(row['ease_factor'])
        interval = int(row['interval'])

        if quality >= 3:
            if reps == 0:
                interval = 1
            elif reps == 1:
                interval = 6
            else:
                interval = int(interval * ef)
            reps += 1
            ef = ef + (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))
        else:
            reps = 0
            interval = 1
        
        if ef < 1.3: ef = 1.3

        next_date = date.today() + timedelta(days=interval)
        return {
            'last_review': date.today().strftime('%Y-%m-%d'),
            'next_review': next_date.strftime('%Y-%m-%d'),
            'interval': interval,
            'repetitions': reps,
            'ease_factor': round(ef, 2),
            'status': 'learning' if reps < 3 else 'review'
        }

class GitHubSync:
    def __init__(self, token, repo_name, file_path="data/vocab.csv"):
        self.token = token
        self.repo_name = repo_name
        self.file_path = file_path
        self.gh = Github(token)

    def pull_data(self):
        try:
            repo = self.gh.get_repo(self.repo_name)
            contents = repo.get_contents(self.file_path)
            csv_str = contents.decoded_content.decode("utf-8")
            df = pd.read_csv(StringIO(csv_str))
            for col in REQUIRED_COLUMNS:
                if col not in df.columns: df[col] = None
            return df
        except Exception as e:
            st.warning(f"GitHub è¯»å–å¤±è´¥ (å¯èƒ½æ˜¯æ–°ä»“åº“): {e}")
            return pd.DataFrame(columns=REQUIRED_COLUMNS)

    def push_data(self, df):
        try:
            repo = self.gh.get_repo(self.repo_name)
            csv_content = df.to_csv(index=False)
            try:
                contents = repo.get_contents(self.file_path)
                repo.update_file(contents.path, f"Update: {date.today()}", csv_content, contents.sha)
                return True, "æ›´æ–°æˆåŠŸ"
            except GithubException:
                repo.create_file(self.file_path, "Initial commit", csv_content)
                return True, "åˆ›å»ºæˆåŠŸ"
        except Exception as e:
            return False, str(e)

# ==============================================================================
# 3. LLM æœåŠ¡é›†æˆ (å®Œå…¨ä»é…ç½®è¯»å–)
# ==============================================================================

def get_llm_explanation(api_key, base_url, model_name, term, context, mode):
    if not api_key:
        return "âš ï¸ è¯·é…ç½® API Key"
    
    client = OpenAI(api_key=api_key, base_url=base_url)
    
    prompts = {
        "explain": f"""
        è¯·ç®€è¦è§£é‡Šæœ¯è¯­ "{term}"ã€‚
        èƒŒæ™¯ä¸Šä¸‹æ–‡ï¼š{context}
        è¦æ±‚ï¼š
        1. ç”¨ä¸€å¥è¯å®šä¹‰ã€‚
        2. ç»™å‡ºä¸€ä¸ªç”Ÿæ´»ä¸­çš„ç±»æ¯”ã€‚
        3. åˆ—å‡º3ä¸ªå…³é”®ç‰¹å¾ã€‚
        ä½¿ç”¨ Markdown æ ¼å¼ã€‚
        """,
        "examples": f"""
        è¯·ä¸º "{term}" ç”Ÿæˆ3ä¸ªä¾‹å¥ã€‚
        è¦æ±‚ï¼šéš¾åº¦é€’å¢ï¼ˆåˆçº§ã€ä¸­çº§ã€é«˜çº§/æ˜“é”™åœºæ™¯ï¼‰ã€‚
        åŒ…å«ä¸­æ–‡ç¿»è¯‘ã€‚
        """,
        "quiz": f"""
        è¯·åŸºäº "{term}" å‡ºä¸€é“å¡«ç©ºé¢˜ã€‚
        ä¸è¦ç›´æ¥æ˜¾ç¤ºç­”æ¡ˆï¼Œå°†ç­”æ¡ˆç”¨ || ç¬¦å·åŒ…è£¹ï¼Œä¾‹å¦‚ ||Answer||ã€‚
        æä¾›ä¸€ä¸ªå¾®å°çš„æç¤ºã€‚
        """
    }
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦ä¹ è¾…å¯¼è€å¸ˆã€‚"},
                {"role": "user", "content": prompts[mode]}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"API Error: {str(e)}"

# ==============================================================================
# 4. Streamlit UI å¸ƒå±€
# ==============================================================================

with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # --- å…³é”®ä¿®æ”¹ï¼šä» Secrets è¯»å–é»˜è®¤å€¼ ---
    # ä½¿ç”¨ st.secrets.get å®‰å…¨è¯»å–ï¼Œé˜²æ­¢ key ä¸å­˜åœ¨æŠ¥é”™
    sec_gh_token = st.secrets.get("GITHUB_TOKEN", "")
    sec_api_key = st.secrets.get("LLM_API_KEY", "")
    sec_base_url = st.secrets.get("LLM_BASE_URL", "https://models.sjtu.edu.cn/api/v1")
    sec_model = st.secrets.get("LLM_MODEL", "DeepSeek-V3-685B")
    
    with st.expander("API é…ç½®", expanded=True):
        # å³ä½¿æœ‰ Secretsï¼Œä¹Ÿå…è®¸ç”¨æˆ·åœ¨ UI ä¸Šä¸´æ—¶è¦†ç›–ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
        gh_token = st.text_input("GitHub Token", value=sec_gh_token, type="password")
        repo_name = st.text_input("Repo Name", value="yourname/memo-app")
        
        st.divider()
        st.caption("LLM æœåŠ¡é…ç½®")
        api_key = st.text_input("API Key", value=sec_api_key, type="password")
        base_url = st.text_input("Base URL", value=sec_base_url)
        model_name = st.text_input("Model Name", value=sec_model)

    st.divider()
    
    st.subheader("ğŸ“š æ•°æ®æ“ä½œ")
    if st.button("ğŸ”„ åŒæ­¥äº‘ç«¯æ•°æ®"):
        if gh_token and repo_name:
            with st.spinner("åŒæ­¥ä¸­..."):
                syncer = GitHubSync(gh_token, repo_name)
                st.session_state.data = syncer.pull_data()
            st.success(f"å·²åŠ è½½ {len(st.session_state.data)} æ¡æ•°æ®")
        else:
            st.error("è¯·å®Œå–„ GitHub é…ç½®")

    uploaded_file = st.file_uploader("å¯¼å…¥ CSV", type=['csv'])
    if uploaded_file:
        new_df = pd.read_csv(uploaded_file)
        if {'term', 'definition'}.issubset(new_df.columns):
            new_df['id'] = [str(uuid.uuid4()) for _ in range(len(new_df))]
            new_df['last_review'] = ""
            new_df['next_review'] = date.today().strftime('%Y-%m-%d')
            new_df['interval'] = 0
            new_df['repetitions'] = 0
            new_df['ease_factor'] = 2.5
            new_df['status'] = 'new'
            for col in REQUIRED_COLUMNS:
                if col not in new_df.columns: new_df[col] = ""
            st.session_state.data = pd.concat([st.session_state.data, new_df[REQUIRED_COLUMNS]], ignore_index=True)
            st.success(f"å·²å¯¼å…¥ {len(new_df)} æ¡æ–°è¯")

    if st.button("â˜ï¸ ä¿å­˜è¿›åº¦"):
        if gh_token and repo_name:
            with st.spinner("ä¿å­˜ä¸­..."):
                syncer = GitHubSync(gh_token, repo_name)
                success, msg = syncer.push_data(st.session_state.data)
                if success: st.toast(msg, icon="âœ…")
                else: st.error(msg)

# --- ä¸»ç•Œé¢ ---

st.title("ğŸ§  è®°å¿†è®­ç»ƒåœº")

today_str = date.today().strftime('%Y-%m-%d')
df = st.session_state.data
valid_date_mask = df['next_review'].notna() & (df['next_review'] != "")
due_mask = valid_date_mask & (df['next_review'] <= today_str)
new_mask = df['status'] == 'new'
review_queue = df[due_mask | new_mask]
count_due = len(review_queue)

col1, col2, col3 = st.columns(3)
col1.metric("ä»Šæ—¥å¾…å¤ä¹ ", f"{count_due}")
col2.metric("æ€»è¯æ¡æ•°", len(df))
status_text = "åœ¨çº¿" if api_key else "æœªé…ç½®"
col3.metric("APIçŠ¶æ€", status_text)

st.divider()

if count_due > 0:
    current_index = review_queue.index[0]
    card = df.loc[current_index]
    
    with st.container(border=True):
        st.markdown(f"### ğŸ“‡ {card['term']}")
        st.caption(f"çŠ¶æ€: {card['status']} | é—´éš”: {card['interval']}å¤©")
        
        with st.expander("ğŸ¤– æ™ºèƒ½åŠ©æ•™"):
            t1, t2, t3 = st.tabs(["ğŸ’¡ æ·±åº¦è§£é‡Š", "ğŸ“ åœºæ™¯ä¾‹å¥", "â“ æ¨¡æ‹Ÿæµ‹è¯•"])
            
            # ä½¿ç”¨ lambda ç®€åŒ–å‚æ•°ä¼ é€’
            call_llm = lambda mode: get_llm_explanation(api_key, base_url, model_name, card['term'], card['context'], mode)
            
            with t1:
                if st.button("ç”Ÿæˆè§£é‡Š"):
                    with st.spinner("åˆ†æä¸­..."):
                        st.markdown(call_llm("explain"))
            with t2:
                if st.button("ç”Ÿæˆä¾‹å¥"):
                    with st.spinner("æ’°å†™ä¸­..."):
                        st.markdown(call_llm("examples"))
            with t3:
                if st.button("ç”Ÿæˆæµ‹è¯•"):
                    with st.spinner("å‡ºé¢˜ä¸­..."):
                        st.markdown(call_llm("quiz"))

        st.write("---")

        if not st.session_state.show_answer:
            st.button("ğŸ‘ï¸ æŸ¥çœ‹èƒŒé¢", on_click=lambda: st.session_state.update(show_answer=True), use_container_width=True)
        else:
            st.markdown("#### ğŸ’¡ ç­”æ¡ˆ")
            st.info(card['definition'])
            if card['context']: st.markdown(f"**å¤‡æ³¨**: {card['context']}")
            
            st.write("---")
            c1, c2, c3 = st.columns(3)
            
            def submit_review(quality):
                new_state = SRSManager.calculate_next_review(card, quality)
                for k, v in new_state.items():
                    st.session_state.data.at[current_index, k] = v
                st.session_state.show_answer = False
                st.toast("å·²æ›´æ–°è®°å¿†æ›²çº¿")
            
            with c1: st.button("ğŸ”´ å¿˜è®°", on_click=submit_review, args=(0,), use_container_width=True)
            with c2: st.button("ğŸŸ¡ æ¨¡ç³Š", on_click=submit_review, args=(3,), use_container_width=True)
            with c3: st.button("ğŸŸ¢ æŒæ¡", on_click=submit_review, args=(5,), use_container_width=True)
else:
    st.balloons()
    st.success("ğŸ‰ ä»Šå¤©çš„å­¦ä¹ è®¡åˆ’å·²å®Œæˆï¼")
    with st.expander("ğŸ“Š æŸ¥çœ‹æ‰€æœ‰è¯æ¡"):
        st.dataframe(st.session_state.data)