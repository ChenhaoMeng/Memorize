import streamlit as st
import pandas as pd
import uuid
import json
import re
import csv
from datetime import date, timedelta
from io import StringIO
from github import Github, GithubException
from openai import OpenAI

# ==============================================================================
# 1. é…ç½®ä¸Žåˆå§‹åŒ–
# ==============================================================================

st.set_page_config(
    page_title="MemoFlow - AIåˆ¶å¡ç‰ˆ",
    page_icon="âš¡",
    layout="wide"
)

# 10åˆ—æ ‡å‡†æ•°æ®ç»“æž„
REQUIRED_COLUMNS = [
    'id', 'term', 'definition', 'context', 
    'last_review', 'next_review', 'interval', 
    'repetitions', 'ease_factor', 'status'
]

# åˆå§‹åŒ– Session State
if 'data' not in st.session_state:
    st.session_state.data = pd.DataFrame(columns=REQUIRED_COLUMNS)
if 'show_answer' not in st.session_state:
    st.session_state.show_answer = False
if 'current_book' not in st.session_state:
    st.session_state.current_book = None 
if 'book_list' not in st.session_state:
    st.session_state.book_list = []

# ==============================================================================
# 2. æ ¸å¿ƒé€»è¾‘ï¼šSM-2 ç®—æ³• & GitHub åŒæ­¥
# ==============================================================================

class SRSManager:
    @staticmethod
    def calculate_next_review(row, quality):
        """SM-2 ç®—æ³• (å¢žåŠ ä¸¥æ ¼çš„ç±»åž‹æ ¡éªŒ)"""
        try:
            reps = int(float(row.get('repetitions', 0)))
            ef = float(row.get('ease_factor', 2.5))
            interval = int(float(row.get('interval', 0)))
        except (ValueError, TypeError):
            reps, ef, interval = 0, 2.5, 0

        if quality >= 3:
            if reps == 0: interval = 1
            elif reps == 1: interval = 6
            else: interval = int(interval * ef)
            reps += 1
            ef = ef + (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))
        else:
            reps = 0
            interval = 1
        
        if ef < 1.3: ef = 1.3

        return {
            'last_review': date.today().strftime('%Y-%m-%d'),
            'next_review': (date.today() + timedelta(days=interval)).strftime('%Y-%m-%d'),
            'interval': interval,
            'repetitions': reps,
            'ease_factor': round(ef, 2),
            'status': 'learning' if reps < 3 else 'review'
        }

class GitHubSync:
    def __init__(self, token, repo_name):
        self.token = token
        self.repo_name = repo_name
        self.gh = Github(token)
        self.data_dir = "data" 

    def get_repo(self):
        return self.gh.get_repo(self.repo_name)

    def list_books(self):
        try:
            repo = self.get_repo()
            contents = repo.get_contents(self.data_dir)
            return [f.name for f in contents if f.name.endswith(".csv")]
        except Exception: return []

    def pull_data(self, filename):
        try:
            repo = self.get_repo()
            path = f"{self.data_dir}/{filename}"
            contents = repo.get_contents(path)
            csv_str = contents.decoded_content.decode("utf-8")
            df = pd.read_csv(StringIO(csv_str), quoting=csv.QUOTE_MINIMAL)
            
            # --- å…³é”®ä¿®å¤ï¼šå…ˆè¡¥é½åˆ—ï¼Œå†æ¸…æ´—æ•°æ® ---
            for col in REQUIRED_COLUMNS:
                if col not in df.columns:
                    if col in ['interval', 'repetitions']: df[col] = 0
                    elif col == 'ease_factor': df[col] = 2.5
                    else: df[col] = ""
            
            # å¼ºåˆ¶ç±»åž‹è½¬æ¢ï¼Œé˜²æ­¢ NaN å¯¼è‡´çš„ ValueError
            df['repetitions'] = pd.to_numeric(df['repetitions'], errors='coerce').fillna(0).astype(int)
            df['interval'] = pd.to_numeric(df['interval'], errors='coerce').fillna(0).astype(int)
            df['ease_factor'] = pd.to_numeric(df['ease_factor'], errors='coerce').fillna(2.5).astype(float)
            df['next_review'] = df['next_review'].replace("", date.today().strftime('%Y-%m-%d'))
            
            return df[REQUIRED_COLUMNS] # ä¿è¯åˆ—é¡ºåºä¸€è‡´
        except Exception as e:
            st.error(f"åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame(columns=REQUIRED_COLUMNS)

    def push_data(self, df, filename):
        try:
            repo = self.get_repo()
            path = f"{self.data_dir}/{filename}"
            # ä½¿ç”¨ QUOTE_NONNUMERIC ç¡®ä¿å¸¦é€—å·çš„å†…å®¹è¢«å¼•å·åŒ…è£¹
            csv_content = df.to_csv(index=False, quoting=csv.QUOTE_NONNUMERIC)
            try:
                contents = repo.get_contents(path)
                repo.update_file(contents.path, f"Update {filename}", csv_content, contents.sha)
            except GithubException:
                repo.create_file(path, f"Create {filename}", csv_content)
            return True, "åŒæ­¥æˆåŠŸ"
        except Exception as e: return False, str(e)

# ==============================================================================
# 3. LLM æœåŠ¡
# ==============================================================================

def stream_llm_explanation(api_key, base_url, model_name, term, context, mode, placeholder):
    if not api_key:
        placeholder.error("âš ï¸ è¯·é…ç½® API Key")
        return
    client = OpenAI(api_key=api_key, base_url=base_url)
    prompts = {
        "explain": f"è¯·ç®€è¦è§£é‡Šæœ¯è¯­ '{term}'ã€‚èƒŒæ™¯ï¼š{context}ã€‚è¦æ±‚ï¼š1.ä¸€å¥è¯å®šä¹‰ã€‚2.ç”Ÿæ´»ç±»æ¯”ã€‚3.ä¸‰ä¸ªå…³é”®ç‚¹ã€‚Markdownæ ¼å¼ã€‚",
        "examples": f"è¯·ä¸º '{term}' ç”Ÿæˆ3ä¸ªä¾‹å¥ï¼ˆåˆçº§/ä¸­çº§/é«˜çº§ï¼‰ï¼ŒåŒ…å«ä¸­æ–‡ç¿»è¯‘ã€‚",
        "quiz": f"åŸºäºŽ '{term}' å‡ºä¸€é“å¡«ç©ºé¢˜ï¼Œç­”æ¡ˆç”¨ || åŒ…è£¹ã€‚"
    }
    try:
        stream = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompts[mode]}],
            stream=True 
        )
        full_response = ""
        for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                placeholder.markdown(full_response + "â–Œ")
        placeholder.markdown(full_response)
    except Exception as e: placeholder.error(f"API Error: {e}")

def generate_ai_card(api_key, base_url, model_name, term):
    if not api_key: return None, "âš ï¸ API Key æœªé…ç½®"
    client = OpenAI(api_key=api_key, base_url=base_url)
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¯å…¸ç¼–çº‚è€…ï¼Œè¯·è¾“å‡º JSONã€‚"},
                      {"role": "user", "content": f"åˆ†æžå•è¯: {term}ï¼ŒåŒ…å« definition å­—æ®µå’Œ context(Markdownæ ¼å¼) å­—æ®µã€‚"}],
            response_format={"type": "json_object"} 
        )
        return json.loads(response.choices[0].message.content), None
    except Exception as e: return None, str(e)

# ==============================================================================
# 4. Streamlit UI
# ==============================================================================

sec_gh_token = st.secrets.get("GITHUB_TOKEN", "")
sec_repo_name = st.secrets.get("GITHUB_REPO", "")
sec_api_key = st.secrets.get("LLM_API_KEY", "")
sec_base_url = st.secrets.get("LLM_BASE_URL", "https://api.deepseek.com")
sec_model = st.secrets.get("LLM_MODEL", "deepseek-chat")

syncer = None

with st.sidebar:
    st.header("ðŸ—‚ï¸ è¯ä¹¦ç®¡ç†")
    with st.expander("ðŸ” ä»“åº“é…ç½®", expanded=not sec_repo_name): 
        gh_token = st.text_input("GitHub Token", value=sec_gh_token, type="password")
        repo_name = st.text_input("Repo Name", value=sec_repo_name)
    
    if gh_token and repo_name:
        syncer = GitHubSync(gh_token, repo_name)

    if syncer:
        if st.button("ðŸ”„ åˆ·æ–°åˆ—è¡¨"): st.session_state.book_list = syncer.list_books()
        selected_book = st.selectbox("é€‰æ‹©è¯ä¹¦", options=st.session_state.book_list)

        if st.button("ðŸ“¥ åŠ è½½è¯ä¹¦", type="primary"):
            if selected_book:
                st.session_state.data = syncer.pull_data(selected_book)
                st.session_state.current_book = selected_book
                st.rerun()

        st.divider()
        tab_ai, tab_csv = st.tabs(["âœ¨ AIåˆ¶å¡", "ðŸ“„ CSVå¯¼å…¥"])
        
        with tab_ai:
            ai_term = st.text_input("æ–°å•è¯")
            if st.button("ðŸª„ ç”Ÿæˆ"):
                res, err = generate_ai_card(sec_api_key, sec_base_url, sec_model, ai_term)
                if res:
                    new_row = {col: "" for col in REQUIRED_COLUMNS}
                    new_row.update({'id': str(uuid.uuid4()), 'term': ai_term, 
                                    'definition': res.get('definition', ''), 'context': res.get('context', ''),
                                    'next_review': date.today().strftime('%Y-%m-%d'), 'ease_factor': 2.5, 'status': 'new', 'interval':0, 'repetitions':0})
                    st.session_state.data = pd.concat([st.session_state.data, pd.DataFrame([new_row])], ignore_index=True)
                    st.success(f"å·²æ·»åŠ  {ai_term}")
        
        with tab_csv:
            up = st.file_uploader("CSVæ–‡ä»¶", type=['csv'])
            if up and st.button("ç¡®è®¤å¯¼å…¥"):
                new_df = pd.read_csv(up)
                new_df['id'] = [str(uuid.uuid4()) for _ in range(len(new_df))]
                st.session_state.data = pd.concat([st.session_state.data, new_df], ignore_index=True).fillna("")
                st.success("å¯¼å…¥æˆåŠŸ")

        if st.button("â˜ï¸ ä¿å­˜è¿›åº¦", type="primary", use_container_width=True):
            if st.session_state.current_book:
                success, msg = syncer.push_data(st.session_state.data, st.session_state.current_book)
                if success: st.toast("åŒæ­¥æˆåŠŸ")
                else: st.error(msg)

# --- å¤ä¹ ç•Œé¢ ---
st.title("ðŸ§  è®°å¿†è®­ç»ƒåœº")

if not st.session_state.current_book:
    st.info("ðŸ‘ˆ è¯·åŠ è½½è¯ä¹¦")
    st.stop()

df = st.session_state.data
today = date.today().strftime('%Y-%m-%d')
due_df = df[(df['next_review'] <= today) | (df['status'] == 'new')]

if not due_df.empty:
    current_index = due_df.index[0]
    card = df.loc[current_index]
    
    with st.container(border=True):
        st.subheader(f"å•è¯: {card['term']}")
        with st.expander("åŠ©æ•™é¢æ¿"):
            res_box = st.empty()
            if st.button("ðŸ’¡ è§£é‡Š"): stream_llm_explanation(sec_api_key, sec_base_url, sec_model, card['term'], card['context'], "explain", res_box)

        if not st.session_state.show_answer:
            if st.button("ðŸ‘ï¸ æ˜¾ç¤ºç­”æ¡ˆ", use_container_width=True):
                st.session_state.show_answer = True
                st.rerun()
        else:
            st.info(f"**å®šä¹‰**: {card['definition']}")
            st.write(card['context'])
            
            c1, c2, c3 = st.columns(3)
            def submit(q):
                res = SRSManager.calculate_next_review(card, q)
                for k, v in res.items(): st.session_state.data.at[current_index, k] = v
                st.session_state.show_answer = False
                # æ³¨æ„ï¼šå›žè°ƒå†…ä¸å†™ rerunï¼Œå›žè°ƒç»“æŸåŽç³»ç»Ÿè‡ªåŠ¨åˆ·
            
            c1.button("ðŸ”´ å¿˜è®°", on_click=submit, args=(0,), use_container_width=True)
            c2.button("ðŸŸ¡ æ¨¡ç³Š", on_click=submit, args=(3,), use_container_width=True)
            c3.button("ðŸŸ¢ æŽŒæ¡", on_click=submit, args=(5,), use_container_width=True)
else:
    st.balloons()
    st.success("å¤ä¹ å®Œæˆï¼")
    st.dataframe(df)
